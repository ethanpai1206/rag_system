import os
import sys
import argparse
from typing import List, Dict, Any, Optional

from llama_index.core import StorageContext, VectorStoreIndex
from llama_index.core.prompts import PromptTemplate
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.llms.openai import OpenAI
from llama_index.vector_stores.milvus import MilvusVectorStore
from llama_index.core.retrievers import VectorIndexRetriever
from mxbai_rerank import MxbaiRerankV2

from shared_config import Config
from logging_config import get_query_logger


class LocalQuerySystem:
    """æœ¬åœ°æŸ¥è©¢ç³»çµ±é¡"""

    def __init__(self):
        """åˆå§‹åŒ–æœ¬åœ°æŸ¥è©¢ç³»çµ±"""
        # åˆå§‹åŒ– loggerï¼ˆåªè¨˜éŒ„åˆ°æ–‡ä»¶ï¼Œä¸é¡¯ç¤ºåœ¨ consoleï¼‰
        self.query_logger = get_query_logger(enable_console=False)

        # é©—è­‰é…ç½®
        Config.validate()

        # è¨­ç½® OpenAI API é‡‘é‘°
        os.environ["OPENAI_API_KEY"] = Config.OPENAI_API_KEY

        # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        self.embed_model = OpenAIEmbedding(model=Config.EMBEDDING_MODEL)

        # åˆå§‹åŒ– LLM
        self.llm = OpenAI(
            model=Config.LLM_MODEL,
            temperature=Config.LLM_TEMPERATURE
        )

        # è‡ªå®šç¾© prompt æ¨¡æ¿
        self.custom_template = PromptTemplate(
            """ä½ æ˜¯ä¸€ä¸ªé—®ç­”æœºå™¨äººã€‚
                ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ä¸‹è¿°ç»™å®šçš„å·²çŸ¥ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

                å·²çŸ¥ä¿¡æ¯:
                {context_str}

                ç”¨æˆ·é—®ï¼š
                {query_str}

                å¦‚æœå·²çŸ¥ä¿¡æ¯ä¸åŒ…å«ç”¨æˆ·é—®é¢˜çš„ç­”æ¡ˆï¼Œæˆ–è€…å·²çŸ¥ä¿¡æ¯ä¸è¶³ä»¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œè¯·ç›´æ¥å›å¤"æˆ‘æ— æ³•å›ç­”æ‚¨çš„é—®é¢˜"ã€‚
                è¯·ä¸è¦è¾“å‡ºå·²çŸ¥ä¿¡æ¯ä¸­ä¸åŒ…å«çš„ä¿¡æ¯æˆ–ç­”æ¡ˆã€‚
                è¯·ç”¨ä¸­æ–‡å›ç­”ç”¨æˆ·é—®é¢˜ã€‚
                """
        )

        # åˆå§‹åŒ–é‡æ’æ¨¡å‹
        self.reranker = MxbaiRerankV2("mixedbread-ai/mxbai-rerank-base-v2")

        # åˆå§‹åŒ–çµ„ä»¶
        self.vector_store = None
        self.index = None
        self.query_engine = None
        self.retriever = None

        # é€£æ¥ Milvus ä¸¦å»ºç«‹ç´¢å¼•
        self._init_system()

    def _init_system(self):
        """åˆå§‹åŒ–ç³»çµ±çµ„ä»¶"""
        try:
            print("æ­£åœ¨é€£æ¥ Milvus...")
            # é€£æ¥åˆ° Milvus
            self.vector_store = MilvusVectorStore(
                host=Config.MILVUS_HOST,
                port=Config.MILVUS_PORT,
                dim=Config.EMBEDDING_DIM,
                collection_name=Config.MILVUS_COLLECTION_NAME,
                overwrite=False
            )
            print(f"âœ“ æˆåŠŸé€£æ¥åˆ° Milvus: {Config.MILVUS_HOST}:{Config.MILVUS_PORT}")

            print("æ­£åœ¨è¼‰å…¥ç´¢å¼•...")
            # å¾ç¾æœ‰çš„å‘é‡å„²å­˜å»ºç«‹ç´¢å¼•
            self.index = VectorStoreIndex.from_vector_store(
                vector_store=self.vector_store,
                embed_model=self.embed_model
            )
            print("âœ“ æˆåŠŸè¼‰å…¥ç´¢å¼•")

            # å»ºç«‹æŸ¥è©¢å¼•æ“ï¼ˆä½¿ç”¨è‡ªå®šç¾© prompt æ¨¡æ¿ï¼‰
            self.query_engine = self.index.as_query_engine(
                similarity_top_k=Config.SIMILARITY_TOP_K,
                response_mode=Config.RESPONSE_MODE,
                llm=self.llm,
                text_qa_template=self.custom_template
            )

            # å»ºç«‹æª¢ç´¢å™¨
            self.retriever = VectorIndexRetriever(
                index=self.index,
                similarity_top_k=Config.SIMILARITY_TOP_K
            )

            print("âœ“ æœ¬åœ°æŸ¥è©¢ç³»çµ±åˆå§‹åŒ–å®Œæˆ\n")

        except Exception as e:
            print(f"âœ— ç³»çµ±åˆå§‹åŒ–å¤±æ•—: {e}")
            print("\nè«‹ç¢ºä¿ï¼š")
            print("1. Milvus æœå‹™å·²å•Ÿå‹•")
            print("2. å·²æœ‰æ•¸æ“šåœ¨ Milvus ä¸­ï¼ˆä½¿ç”¨ document_indexing.py å…ˆå…¥åº«æ•¸æ“šï¼‰")
            print("3. OpenAI API é‡‘é‘°è¨­ç½®æ­£ç¢º")
            sys.exit(1)

    def query(self, question: str, top_k: Optional[int] = None, show_sources: bool = True, use_rerank: bool = False) -> Dict[str, Any]:
        """
        åŸ·è¡Œå•ç­”æŸ¥è©¢

        Args:
            question: å•é¡Œ
            top_k: æª¢ç´¢æ–‡æª”æ•¸é‡
            show_sources: æ˜¯å¦é¡¯ç¤ºä¾†æº
            use_rerank: æ˜¯å¦ä½¿ç”¨é‡æ’æ¨¡å‹

        Returns:
            æŸ¥è©¢çµæœ
        """
        import time

        start_time = time.time()

        try:
            print(f"ğŸ” æŸ¥è©¢å•é¡Œ: {question}")

            if use_rerank:
                # ä½¿ç”¨é‡æ’æ¨¡å‹çš„æŸ¥è©¢æµç¨‹
                print("ğŸ”„ ä½¿ç”¨é‡æ’æ¨¡å‹é€²è¡ŒæŸ¥è©¢...")

                # å…ˆæª¢ç´¢è¼ƒå¤šçš„æ–‡æª”ç”¨æ–¼é‡æ’
                retrieve_count = (top_k or Config.SIMILARITY_TOP_K) * 2
                retriever = VectorIndexRetriever(
                    index=self.index,
                    similarity_top_k=retrieve_count
                )
                nodes = retriever.retrieve(question)

                # æº–å‚™æ–‡æª”åˆ—è¡¨ç”¨æ–¼é‡æ’
                documents = [node.text for node in nodes]

                # ä½¿ç”¨é‡æ’æ¨¡å‹
                rerank_results = self.reranker.rank(
                    question,
                    documents,
                    return_documents=True,
                    top_k=top_k or Config.SIMILARITY_TOP_K
                )

                print(f"âœ“ é‡æ’å®Œæˆï¼Œé¸å‡ºå‰ {len(rerank_results)} å€‹æœ€ç›¸é—œæ–‡æª”")

                # é‡æ–°æ§‹å»ºä¸Šä¸‹æ–‡
                reranked_context = "\n\n".join([result.document for result in rerank_results])

                # ç›´æ¥ä½¿ç”¨ LLM ç”Ÿæˆå›ç­”
                prompt = self.custom_template.format(
                    context_str=reranked_context,
                    query_str=question
                )

                response_text = self.llm.complete(prompt).text

                # æ¨¡æ“¬å›æ‡‰ç‰©ä»¶
                class MockResponse:
                    def __init__(self, text, source_nodes):
                        self.text = text
                        self.source_nodes = source_nodes

                    def __str__(self):
                        return self.text

                # æ ¹æ“šé‡æ’çµæœé‡æ–°çµ„ç¹” source_nodes
                reranked_nodes = []
                for i, result in enumerate(rerank_results):
                    # æ‰¾åˆ°å°æ‡‰çš„åŸå§‹ç¯€é»
                    for node in nodes:
                        if node.text == result.document:
                            node.score = result.score
                            reranked_nodes.append(node)
                            break

                response = MockResponse(response_text, reranked_nodes)

            else:
                # åŸæœ‰çš„æŸ¥è©¢æµç¨‹ï¼ˆä¸ä½¿ç”¨é‡æ’ï¼‰
                if top_k and top_k != Config.SIMILARITY_TOP_K:
                    query_engine = self.index.as_query_engine(
                        similarity_top_k=top_k,
                        response_mode=Config.RESPONSE_MODE,
                        llm=self.llm,
                        text_qa_template=self.custom_template
                    )
                    response = query_engine.query(question)
                else:
                    response = self.query_engine.query(question)

            # è™•ç†å›æ‡‰
            answer = str(response)
            processing_time = time.time() - start_time

            print(f"\nğŸ’¬ å›ç­”:")
            print(answer)
            print(f"\nâ±ï¸  è™•ç†æ™‚é–“: {processing_time:.2f} ç§’")

            # è™•ç†ä¾†æºè³‡è¨Šï¼ˆåªè¨˜éŒ„åˆ° log æ–‡ä»¶ï¼Œä¸åœ¨ console é¡¯ç¤ºï¼‰
            sources = []
            if show_sources and hasattr(response, 'source_nodes'):
                # çµ„ç¹”å®Œæ•´çš„ä¾†æºè³‡è¨Šç”¨æ–¼ log è¨˜éŒ„
                sources_log = "\nğŸ“š åƒè€ƒä¾†æº:\n"

                for i, node in enumerate(response.source_nodes, 1):
                    score = node.score if hasattr(node, 'score') else 0.0
                    metadata = node.metadata if hasattr(node, 'metadata') else {}

                    sources_log += f"\n{i}. ç›¸ä¼¼åº¦åˆ†æ•¸: {score:.4f}\n"
                    if 'source' in metadata:
                        sources_log += f"   ä¾†æº: {metadata['source']}\n"
                    if 'paragraph_id' in metadata:
                        sources_log += f"   æ®µè½ ID: {metadata['paragraph_id']}\n"

                    # è¨˜éŒ„å®Œæ•´å…§å®¹åˆ° log
                    sources_log += f"   å…§å®¹: {node.text}\n"

                    source_info = {
                        "text": node.text,
                        "score": score,
                        "metadata": metadata
                    }
                    sources.append(source_info)

                # åªè¨˜éŒ„åˆ° log æ–‡ä»¶ï¼Œä¸åœ¨ console é¡¯ç¤º
                self.query_logger.log_info(sources_log)

            result = {
                "question": question,
                "answer": answer,
                "sources": sources,
                "processing_time": processing_time
            }

            # è¨˜éŒ„æŸ¥è©¢çµæœåˆ° log æ–‡ä»¶
            self.query_logger.log_query_result(result)

            return result

        except Exception as e:
            print(f"âœ— æŸ¥è©¢å¤±æ•—: {e}")
            return {
                "question": question,
                "answer": f"æŸ¥è©¢å¤±æ•—: {e}",
                "sources": [],
                "processing_time": 0.0
            }

    def get_relevant_documents(self, question: str, top_k: Optional[int] = None) -> List[Dict[str, Any]]:
        """
        ç²å–ç›¸é—œæ–‡æª”

        Args:
            question: å•é¡Œ
            top_k: æª¢ç´¢æ–‡æª”æ•¸é‡

        Returns:
            ç›¸é—œæ–‡æª”åˆ—è¡¨
        """
        try:
            print(f"ğŸ” æª¢ç´¢ç›¸é—œæ–‡æª”: {question}")

            # è¨­ç½®æª¢ç´¢æ•¸é‡
            retrieve_count = top_k or Config.SIMILARITY_TOP_K

            # å¦‚æœéœ€è¦è‡¨æ™‚èª¿æ•´æª¢ç´¢æ•¸é‡
            if top_k and top_k != Config.SIMILARITY_TOP_K:
                retriever = VectorIndexRetriever(
                    index=self.index,
                    similarity_top_k=top_k
                )
                nodes = retriever.retrieve(question)
            else:
                nodes = self.retriever.retrieve(question)

            # è™•ç†æª¢ç´¢çµæœ
            documents = []
            print(f"\nğŸ“„ æ‰¾åˆ° {len(nodes)} å€‹ç›¸é—œæ–‡æª”:")

            for i, node in enumerate(nodes, 1):
                score = node.score if hasattr(node, 'score') else 0.0
                metadata = node.metadata if hasattr(node, 'metadata') else {}

                print(f"\n{i}. ç›¸ä¼¼åº¦åˆ†æ•¸: {score:.4f}")
                if 'source' in metadata:
                    print(f"   ä¾†æº: {metadata['source']}")
                if 'paragraph_id' in metadata:
                    print(f"   æ®µè½ ID: {metadata['paragraph_id']}")

                # é¡¯ç¤ºæ–‡æœ¬ç‰‡æ®µ
                print(f"   å…§å®¹: {node.text}")
                print("-" * 80)

                doc_info = {
                    "text": node.text,
                    "score": score,
                    "metadata": metadata
                }
                documents.append(doc_info)

            return documents

        except Exception as e:
            print(f"âœ— æ–‡æª”æª¢ç´¢å¤±æ•—: {e}")
            return []

    def interactive_mode(self):
        """äº¤äº’å¼æŸ¥è©¢æ¨¡å¼"""
        print("ğŸ¯ é€²å…¥äº¤äº’å¼æŸ¥è©¢æ¨¡å¼")
        print("è¼¸å…¥ 'quit' æˆ– 'exit' é€€å‡º")
        print("è¼¸å…¥ 'docs <å•é¡Œ>' åƒ…æª¢ç´¢ç›¸é—œæ–‡æª”")
        print("è¼¸å…¥ 'help' æŸ¥çœ‹å‘½ä»¤èªªæ˜")
        print("-" * 50)

        while True:
            try:
                user_input = input("\nè«‹è¼¸å…¥æ‚¨çš„å•é¡Œ: ").strip()

                if not user_input:
                    continue

                if user_input.lower() in ['quit', 'exit', 'q']:
                    print("ğŸ‘‹ å†è¦‹ï¼")
                    break

                if user_input.lower() == 'help':
                    self._show_help()
                    continue

                if user_input.lower().startswith('docs '):
                    # åƒ…æª¢ç´¢æ–‡æª”æ¨¡å¼
                    question = user_input[5:].strip()
                    if question:
                        self.get_relevant_documents(question)
                    else:
                        print("âŒ è«‹æä¾›è¦æª¢ç´¢çš„å•é¡Œ")
                    continue

                # æ­£å¸¸å•ç­”æ¨¡å¼
                self.query(user_input)

            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ å†è¦‹ï¼")
                break
            except Exception as e:
                print(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}")

    def _show_help(self):
        """é¡¯ç¤ºå¹«åŠ©ä¿¡æ¯"""
        print("\nğŸ“– å‘½ä»¤èªªæ˜:")
        print("â€¢ ç›´æ¥è¼¸å…¥å•é¡Œ - é€²è¡Œå•ç­”æŸ¥è©¢")
        print("â€¢ docs <å•é¡Œ> - åƒ…æª¢ç´¢ç›¸é—œæ–‡æª”ï¼Œä¸ç”Ÿæˆå›ç­”")
        print("â€¢ help - é¡¯ç¤ºæ­¤å¹«åŠ©ä¿¡æ¯")
        print("â€¢ quit/exit/q - é€€å‡ºç¨‹åº")

    def batch_query(self, questions: List[str], output_file: Optional[str] = None):
        """
        æ‰¹æ¬¡æŸ¥è©¢

        Args:
            questions: å•é¡Œåˆ—è¡¨
            output_file: è¼¸å‡ºæ–‡ä»¶è·¯å¾‘
        """
        results = []

        print(f"ğŸ”„ é–‹å§‹æ‰¹æ¬¡æŸ¥è©¢ {len(questions)} å€‹å•é¡Œ...")

        for i, question in enumerate(questions, 1):
            print(f"\n[{i}/{len(questions)}] è™•ç†ä¸­...")
            result = self.query(question, show_sources=False)
            results.append(result)
            print("=" * 80)

        if output_file:
            try:
                import json
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(results, f, ensure_ascii=False, indent=2)
                print(f"\nâœ… çµæœå·²ä¿å­˜åˆ°: {output_file}")
            except Exception as e:
                print(f"âŒ ä¿å­˜æ–‡ä»¶å¤±æ•—: {e}")

        return results


def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(description="æœ¬åœ° RAG æŸ¥è©¢å·¥å…·")
    parser.add_argument("--question", "-q", type=str, help="å–®æ¬¡æŸ¥è©¢å•é¡Œ")
    parser.add_argument("--docs", "-d", type=str, help="æª¢ç´¢ç›¸é—œæ–‡æª”")
    parser.add_argument("--top-k", "-k", type=int, help="æª¢ç´¢æ–‡æª”æ•¸é‡")
    parser.add_argument("--interactive", "-i", action="store_true", help="äº¤äº’å¼æ¨¡å¼")
    parser.add_argument("--batch", "-b", nargs="+", help="æ‰¹æ¬¡æŸ¥è©¢å•é¡Œåˆ—è¡¨")
    parser.add_argument("--output", "-o", type=str, help="è¼¸å‡ºæ–‡ä»¶è·¯å¾‘ï¼ˆæ‰¹æ¬¡æ¨¡å¼ï¼‰")
    parser.add_argument("--no-sources", action="store_true", help="ä¸é¡¯ç¤ºä¾†æºä¿¡æ¯")
    parser.add_argument("--no-rerank", action="store_true", help="ä¸ä½¿ç”¨é‡æ’æ¨¡å‹")

    args = parser.parse_args()

    # åˆå§‹åŒ–æŸ¥è©¢ç³»çµ±
    try:
        query_system = LocalQuerySystem()
    except Exception as e:
        print(f"ç³»çµ±åˆå§‹åŒ–å¤±æ•—: {e}")
        return

    if args.question:
        # å–®æ¬¡æŸ¥è©¢æ¨¡å¼
        query_system.query(
            args.question,
            args.top_k,
            show_sources=not args.no_sources,
            use_rerank=not args.no_rerank
        )

    elif args.docs:
        # æ–‡æª”æª¢ç´¢æ¨¡å¼
        query_system.get_relevant_documents(args.docs, args.top_k)

    elif args.batch:
        # æ‰¹æ¬¡æŸ¥è©¢æ¨¡å¼
        query_system.batch_query(args.batch, args.output)

    elif args.interactive:
        # äº¤äº’å¼æ¨¡å¼
        query_system.interactive_mode()

    else:
        # é»˜èªé€²å…¥äº¤äº’å¼æ¨¡å¼
        print("æœªæŒ‡å®šæŸ¥è©¢æ¨¡å¼ï¼Œé€²å…¥äº¤äº’å¼æ¨¡å¼...")
        query_system.interactive_mode()


if __name__ == "__main__":
    main()